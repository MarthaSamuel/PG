{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Anomaly detection with Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U3V7pIJJ8Mn"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQN5RAOJ8Mw",
        "outputId": "abe45a3b-bc2e-4d99-ad3c-a1543c4e7613"
      },
      "source": [
        "data = pd.read_csv(\"ecg.csv\", header=None)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.112522</td>\n",
              "      <td>-2.827204</td>\n",
              "      <td>-3.773897</td>\n",
              "      <td>-4.349751</td>\n",
              "      <td>-4.376041</td>\n",
              "      <td>-3.474986</td>\n",
              "      <td>-2.181408</td>\n",
              "      <td>-1.818287</td>\n",
              "      <td>-1.250522</td>\n",
              "      <td>-0.477492</td>\n",
              "      <td>...</td>\n",
              "      <td>0.792168</td>\n",
              "      <td>0.933541</td>\n",
              "      <td>0.796958</td>\n",
              "      <td>0.578621</td>\n",
              "      <td>0.257740</td>\n",
              "      <td>0.228077</td>\n",
              "      <td>0.123431</td>\n",
              "      <td>0.925286</td>\n",
              "      <td>0.193137</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.100878</td>\n",
              "      <td>-3.996840</td>\n",
              "      <td>-4.285843</td>\n",
              "      <td>-4.506579</td>\n",
              "      <td>-4.022377</td>\n",
              "      <td>-3.234368</td>\n",
              "      <td>-1.566126</td>\n",
              "      <td>-0.992258</td>\n",
              "      <td>-0.754680</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.538356</td>\n",
              "      <td>0.656881</td>\n",
              "      <td>0.787490</td>\n",
              "      <td>0.724046</td>\n",
              "      <td>0.555784</td>\n",
              "      <td>0.476333</td>\n",
              "      <td>0.773820</td>\n",
              "      <td>1.119621</td>\n",
              "      <td>-1.436250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.567088</td>\n",
              "      <td>-2.593450</td>\n",
              "      <td>-3.874230</td>\n",
              "      <td>-4.584095</td>\n",
              "      <td>-4.187449</td>\n",
              "      <td>-3.151462</td>\n",
              "      <td>-1.742940</td>\n",
              "      <td>-1.490658</td>\n",
              "      <td>-1.183580</td>\n",
              "      <td>-0.394229</td>\n",
              "      <td>...</td>\n",
              "      <td>0.886073</td>\n",
              "      <td>0.531452</td>\n",
              "      <td>0.311377</td>\n",
              "      <td>-0.021919</td>\n",
              "      <td>-0.713683</td>\n",
              "      <td>-0.532197</td>\n",
              "      <td>0.321097</td>\n",
              "      <td>0.904227</td>\n",
              "      <td>-0.421797</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.490473</td>\n",
              "      <td>-1.914407</td>\n",
              "      <td>-3.616364</td>\n",
              "      <td>-4.318823</td>\n",
              "      <td>-4.268016</td>\n",
              "      <td>-3.881110</td>\n",
              "      <td>-2.993280</td>\n",
              "      <td>-1.671131</td>\n",
              "      <td>-1.333884</td>\n",
              "      <td>-0.965629</td>\n",
              "      <td>...</td>\n",
              "      <td>0.350816</td>\n",
              "      <td>0.499111</td>\n",
              "      <td>0.600345</td>\n",
              "      <td>0.842069</td>\n",
              "      <td>0.952074</td>\n",
              "      <td>0.990133</td>\n",
              "      <td>1.086798</td>\n",
              "      <td>1.403011</td>\n",
              "      <td>-0.383564</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800232</td>\n",
              "      <td>-0.874252</td>\n",
              "      <td>-2.384761</td>\n",
              "      <td>-3.973292</td>\n",
              "      <td>-4.338224</td>\n",
              "      <td>-3.802422</td>\n",
              "      <td>-2.534510</td>\n",
              "      <td>-1.783423</td>\n",
              "      <td>-1.594450</td>\n",
              "      <td>-0.753199</td>\n",
              "      <td>...</td>\n",
              "      <td>1.148884</td>\n",
              "      <td>0.958434</td>\n",
              "      <td>1.059025</td>\n",
              "      <td>1.371682</td>\n",
              "      <td>1.277392</td>\n",
              "      <td>0.960304</td>\n",
              "      <td>0.971020</td>\n",
              "      <td>1.614392</td>\n",
              "      <td>1.421456</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 141 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.112522 -2.827204 -3.773897 -4.349751 -4.376041 -3.474986 -2.181408   \n",
              "1 -1.100878 -3.996840 -4.285843 -4.506579 -4.022377 -3.234368 -1.566126   \n",
              "2 -0.567088 -2.593450 -3.874230 -4.584095 -4.187449 -3.151462 -1.742940   \n",
              "3  0.490473 -1.914407 -3.616364 -4.318823 -4.268016 -3.881110 -2.993280   \n",
              "4  0.800232 -0.874252 -2.384761 -3.973292 -4.338224 -3.802422 -2.534510   \n",
              "\n",
              "        7         8         9    ...       131       132       133       134  \\\n",
              "0 -1.818287 -1.250522 -0.477492  ...  0.792168  0.933541  0.796958  0.578621   \n",
              "1 -0.992258 -0.754680  0.042321  ...  0.538356  0.656881  0.787490  0.724046   \n",
              "2 -1.490658 -1.183580 -0.394229  ...  0.886073  0.531452  0.311377 -0.021919   \n",
              "3 -1.671131 -1.333884 -0.965629  ...  0.350816  0.499111  0.600345  0.842069   \n",
              "4 -1.783423 -1.594450 -0.753199  ...  1.148884  0.958434  1.059025  1.371682   \n",
              "\n",
              "        135       136       137       138       139  140  \n",
              "0  0.257740  0.228077  0.123431  0.925286  0.193137  1.0  \n",
              "1  0.555784  0.476333  0.773820  1.119621 -1.436250  1.0  \n",
              "2 -0.713683 -0.532197  0.321097  0.904227 -0.421797  1.0  \n",
              "3  0.952074  0.990133  1.086798  1.403011 -0.383564  1.0  \n",
              "4  1.277392  0.960304  0.971020  1.614392  1.421456  1.0  \n",
              "\n",
              "[5 rows x 141 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv_4CVB9J8Mz",
        "outputId": "9ce7d5ac-ff8a-4b7c-c6d1-b6e6bd4106d9"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4998, 141)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BspRIPtyJ8M0",
        "outputId": "0d008d0d-5c6b-4c6c-e087-133beb938ad7"
      },
      "source": [
        "data.iloc[:, 140].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNNbd_twJ8M1",
        "outputId": "967d766f-9970-4d58-b6c3-80e486e987a0"
      },
      "source": [
        "data.iloc[:, 140].value_counts() #here anomaly is 0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0    2919\n",
              "0.0    2079\n",
              "Name: 140, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzUN03IIJ8M2"
      },
      "source": [
        "# 1 = normal, 0= anomaly\n",
        "\n",
        "# Autoncoder(normal, normal)\n",
        "# test = normal, abnormal\n",
        "\n",
        "# if abnormal or anormaly, the error will be %more than threshold\n",
        "\n",
        "\n",
        "\n",
        "output = 140\n",
        "\n",
        "features = data.drop(output, axis=1)\n",
        "target = data[output]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(features, target, test_size=0.2, random_state=12)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_iRWtL9J8M4"
      },
      "source": [
        "index1 = ytrain[ytrain==1].index\n",
        "train_data = xtrain.loc[index1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2IRuI6TJ8M6",
        "outputId": "cd6a2484-ff1a-4088-c527-eb1e26129636"
      },
      "source": [
        "train_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "      <td>2341.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.363114</td>\n",
              "      <td>-2.188318</td>\n",
              "      <td>-3.285956</td>\n",
              "      <td>-3.956670</td>\n",
              "      <td>-3.862388</td>\n",
              "      <td>-3.252929</td>\n",
              "      <td>-2.284570</td>\n",
              "      <td>-1.625319</td>\n",
              "      <td>-1.188511</td>\n",
              "      <td>-0.640521</td>\n",
              "      <td>...</td>\n",
              "      <td>0.786358</td>\n",
              "      <td>0.954087</td>\n",
              "      <td>1.040210</td>\n",
              "      <td>1.009256</td>\n",
              "      <td>0.885146</td>\n",
              "      <td>0.619349</td>\n",
              "      <td>0.501843</td>\n",
              "      <td>0.478040</td>\n",
              "      <td>0.556952</td>\n",
              "      <td>-0.530895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.265193</td>\n",
              "      <td>1.425413</td>\n",
              "      <td>1.007282</td>\n",
              "      <td>0.717215</td>\n",
              "      <td>0.567791</td>\n",
              "      <td>0.722397</td>\n",
              "      <td>0.693480</td>\n",
              "      <td>0.466291</td>\n",
              "      <td>0.494758</td>\n",
              "      <td>0.507413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.617147</td>\n",
              "      <td>0.579412</td>\n",
              "      <td>0.564822</td>\n",
              "      <td>0.707281</td>\n",
              "      <td>0.880111</td>\n",
              "      <td>0.992202</td>\n",
              "      <td>1.014683</td>\n",
              "      <td>1.028462</td>\n",
              "      <td>1.033286</td>\n",
              "      <td>1.259144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-6.729499</td>\n",
              "      <td>-7.090374</td>\n",
              "      <td>-5.110389</td>\n",
              "      <td>-5.363241</td>\n",
              "      <td>-5.375715</td>\n",
              "      <td>-5.330194</td>\n",
              "      <td>-4.782240</td>\n",
              "      <td>-3.940538</td>\n",
              "      <td>-3.163394</td>\n",
              "      <td>-2.197911</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.927187</td>\n",
              "      <td>-1.897036</td>\n",
              "      <td>-1.858455</td>\n",
              "      <td>-2.312900</td>\n",
              "      <td>-2.595044</td>\n",
              "      <td>-3.122098</td>\n",
              "      <td>-3.736786</td>\n",
              "      <td>-4.644772</td>\n",
              "      <td>-4.252266</td>\n",
              "      <td>-5.094438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.230640</td>\n",
              "      <td>-3.196051</td>\n",
              "      <td>-4.027654</td>\n",
              "      <td>-4.415411</td>\n",
              "      <td>-4.194735</td>\n",
              "      <td>-3.745008</td>\n",
              "      <td>-2.774874</td>\n",
              "      <td>-1.834483</td>\n",
              "      <td>-1.530351</td>\n",
              "      <td>-0.990263</td>\n",
              "      <td>...</td>\n",
              "      <td>0.474887</td>\n",
              "      <td>0.727503</td>\n",
              "      <td>0.797492</td>\n",
              "      <td>0.747136</td>\n",
              "      <td>0.524796</td>\n",
              "      <td>0.180468</td>\n",
              "      <td>0.024440</td>\n",
              "      <td>-0.100192</td>\n",
              "      <td>-0.142556</td>\n",
              "      <td>-1.391791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.495060</td>\n",
              "      <td>-2.428306</td>\n",
              "      <td>-3.484443</td>\n",
              "      <td>-4.151610</td>\n",
              "      <td>-3.934232</td>\n",
              "      <td>-3.334455</td>\n",
              "      <td>-2.200637</td>\n",
              "      <td>-1.628054</td>\n",
              "      <td>-1.284621</td>\n",
              "      <td>-0.625056</td>\n",
              "      <td>...</td>\n",
              "      <td>0.914641</td>\n",
              "      <td>1.047064</td>\n",
              "      <td>1.112452</td>\n",
              "      <td>1.132088</td>\n",
              "      <td>1.057633</td>\n",
              "      <td>0.824350</td>\n",
              "      <td>0.736966</td>\n",
              "      <td>0.706741</td>\n",
              "      <td>0.740470</td>\n",
              "      <td>-0.471432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.466564</td>\n",
              "      <td>-1.378322</td>\n",
              "      <td>-2.787035</td>\n",
              "      <td>-3.682342</td>\n",
              "      <td>-3.640484</td>\n",
              "      <td>-2.813190</td>\n",
              "      <td>-1.807586</td>\n",
              "      <td>-1.438637</td>\n",
              "      <td>-0.938966</td>\n",
              "      <td>-0.334908</td>\n",
              "      <td>...</td>\n",
              "      <td>1.196058</td>\n",
              "      <td>1.309012</td>\n",
              "      <td>1.373264</td>\n",
              "      <td>1.437701</td>\n",
              "      <td>1.458331</td>\n",
              "      <td>1.297573</td>\n",
              "      <td>1.191907</td>\n",
              "      <td>1.215522</td>\n",
              "      <td>1.303870</td>\n",
              "      <td>0.384981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.966414</td>\n",
              "      <td>3.351136</td>\n",
              "      <td>1.628389</td>\n",
              "      <td>0.321795</td>\n",
              "      <td>0.566366</td>\n",
              "      <td>0.959135</td>\n",
              "      <td>1.435708</td>\n",
              "      <td>1.471382</td>\n",
              "      <td>1.683730</td>\n",
              "      <td>1.898627</td>\n",
              "      <td>...</td>\n",
              "      <td>2.550441</td>\n",
              "      <td>3.007606</td>\n",
              "      <td>2.797992</td>\n",
              "      <td>2.816664</td>\n",
              "      <td>2.824053</td>\n",
              "      <td>3.071365</td>\n",
              "      <td>3.206815</td>\n",
              "      <td>3.185404</td>\n",
              "      <td>2.900218</td>\n",
              "      <td>3.025085</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 140 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0            1            2            3            4    \\\n",
              "count  2341.000000  2341.000000  2341.000000  2341.000000  2341.000000   \n",
              "mean     -0.363114    -2.188318    -3.285956    -3.956670    -3.862388   \n",
              "std       1.265193     1.425413     1.007282     0.717215     0.567791   \n",
              "min      -6.729499    -7.090374    -5.110389    -5.363241    -5.375715   \n",
              "25%      -1.230640    -3.196051    -4.027654    -4.415411    -4.194735   \n",
              "50%      -0.495060    -2.428306    -3.484443    -4.151610    -3.934232   \n",
              "75%       0.466564    -1.378322    -2.787035    -3.682342    -3.640484   \n",
              "max       4.966414     3.351136     1.628389     0.321795     0.566366   \n",
              "\n",
              "               5            6            7            8            9    ...  \\\n",
              "count  2341.000000  2341.000000  2341.000000  2341.000000  2341.000000  ...   \n",
              "mean     -3.252929    -2.284570    -1.625319    -1.188511    -0.640521  ...   \n",
              "std       0.722397     0.693480     0.466291     0.494758     0.507413  ...   \n",
              "min      -5.330194    -4.782240    -3.940538    -3.163394    -2.197911  ...   \n",
              "25%      -3.745008    -2.774874    -1.834483    -1.530351    -0.990263  ...   \n",
              "50%      -3.334455    -2.200637    -1.628054    -1.284621    -0.625056  ...   \n",
              "75%      -2.813190    -1.807586    -1.438637    -0.938966    -0.334908  ...   \n",
              "max       0.959135     1.435708     1.471382     1.683730     1.898627  ...   \n",
              "\n",
              "               130          131          132          133          134  \\\n",
              "count  2341.000000  2341.000000  2341.000000  2341.000000  2341.000000   \n",
              "mean      0.786358     0.954087     1.040210     1.009256     0.885146   \n",
              "std       0.617147     0.579412     0.564822     0.707281     0.880111   \n",
              "min      -1.927187    -1.897036    -1.858455    -2.312900    -2.595044   \n",
              "25%       0.474887     0.727503     0.797492     0.747136     0.524796   \n",
              "50%       0.914641     1.047064     1.112452     1.132088     1.057633   \n",
              "75%       1.196058     1.309012     1.373264     1.437701     1.458331   \n",
              "max       2.550441     3.007606     2.797992     2.816664     2.824053   \n",
              "\n",
              "               135          136          137          138          139  \n",
              "count  2341.000000  2341.000000  2341.000000  2341.000000  2341.000000  \n",
              "mean      0.619349     0.501843     0.478040     0.556952    -0.530895  \n",
              "std       0.992202     1.014683     1.028462     1.033286     1.259144  \n",
              "min      -3.122098    -3.736786    -4.644772    -4.252266    -5.094438  \n",
              "25%       0.180468     0.024440    -0.100192    -0.142556    -1.391791  \n",
              "50%       0.824350     0.736966     0.706741     0.740470    -0.471432  \n",
              "75%       1.297573     1.191907     1.215522     1.303870     0.384981  \n",
              "max       3.071365     3.206815     3.185404     2.900218     3.025085  \n",
              "\n",
              "[8 rows x 140 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_FU3iN2J8M8"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler  #because it preserves range\n",
        "\n",
        "mm = MinMaxScaler(feature_range=(0,1))\n",
        "train_scaled = mm.fit_transform(train_data)\n",
        "test_scaled = mm.transform(xtest)\n",
        "\n",
        "\n",
        "#fit = learn\n",
        "#transform = apply"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQYdvs1-J8M9"
      },
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "class Autoencoder(Model):\n",
        "    def __init__(self, decode_units, encode_units):\n",
        "        super().__init__()\n",
        "        self.encoder = Sequential([\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(16, activation='relu'),\n",
        "            Dense(encode_units, activation='relu'),\n",
        "\n",
        "        ])\n",
        "        \n",
        "        self.decoder = Sequential([\n",
        "            Dense(16, activation='relu'),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(decode_units, activation='sigmoid'),\n",
        "\n",
        "        ])\n",
        "    \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        encoder_output = self.encoder(inputs)\n",
        "        decoder_output = self.decoder(encoder_output)\n",
        "        return decoder_output\n",
        "        \n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aHnGfwyJ8M_"
      },
      "source": [
        "model = Autoencoder(decode_units= train_scaled.shape[1], encode_units=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVg3oqb4J8M_"
      },
      "source": [
        "model.compile(loss= 'msle', metrics=['mse'], optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgabbTyOJ8NA",
        "outputId": "032e7e3e-2e1b-43c9-90a1-8c2cda3ea42c"
      },
      "source": [
        "history = model.fit(train_scaled, train_scaled,\n",
        "         epochs=50,\n",
        "         batch_size=512,\n",
        "         validation_data=(test_scaled, test_scaled))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0020 - mse: 0.0046 - val_loss: 0.0075 - val_mse: 0.0175\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - mse: 0.0045 - val_loss: 0.0075 - val_mse: 0.0174\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - mse: 0.0043 - val_loss: 0.0074 - val_mse: 0.0171\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0019 - mse: 0.0042 - val_loss: 0.0074 - val_mse: 0.0173\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - mse: 0.0041 - val_loss: 0.0073 - val_mse: 0.0169\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0040 - val_loss: 0.0071 - val_mse: 0.0166\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0039 - val_loss: 0.0069 - val_mse: 0.0162\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - mse: 0.0038 - val_loss: 0.0068 - val_mse: 0.0160\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0038 - val_loss: 0.0067 - val_mse: 0.0156\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - mse: 0.0037 - val_loss: 0.0066 - val_mse: 0.0155\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0016 - mse: 0.0036 - val_loss: 0.0066 - val_mse: 0.0154\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - mse: 0.0036 - val_loss: 0.0064 - val_mse: 0.0150\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - mse: 0.0035 - val_loss: 0.0064 - val_mse: 0.0149\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0016 - mse: 0.0035 - val_loss: 0.0063 - val_mse: 0.0148\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0035 - val_loss: 0.0062 - val_mse: 0.0146\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0015 - mse: 0.0034 - val_loss: 0.0061 - val_mse: 0.0144\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0034 - val_loss: 0.0061 - val_mse: 0.0143\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0015 - mse: 0.0033 - val_loss: 0.0060 - val_mse: 0.0142\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0033 - val_loss: 0.0060 - val_mse: 0.0141\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0033 - val_loss: 0.0059 - val_mse: 0.0140\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0032 - val_loss: 0.0059 - val_mse: 0.0138\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0014 - mse: 0.0032 - val_loss: 0.0058 - val_mse: 0.0137\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0032 - val_loss: 0.0058 - val_mse: 0.0137\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0032 - val_loss: 0.0058 - val_mse: 0.0136\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0032 - val_loss: 0.0057 - val_mse: 0.0134\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0031 - val_loss: 0.0057 - val_mse: 0.0133\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0031 - val_loss: 0.0057 - val_mse: 0.0134\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0031 - val_loss: 0.0056 - val_mse: 0.0132\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0031 - val_loss: 0.0056 - val_mse: 0.0131\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0030 - val_loss: 0.0055 - val_mse: 0.0130\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0030 - val_loss: 0.0055 - val_mse: 0.0129\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0030 - val_loss: 0.0054 - val_mse: 0.0129\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0030 - val_loss: 0.0054 - val_mse: 0.0128\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0030 - val_loss: 0.0054 - val_mse: 0.0127\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0030 - val_loss: 0.0054 - val_mse: 0.0127\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0029 - val_loss: 0.0054 - val_mse: 0.0127\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0029 - val_loss: 0.0053 - val_mse: 0.0126\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0029 - val_loss: 0.0053 - val_mse: 0.0126\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0029 - val_loss: 0.0053 - val_mse: 0.0125\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0029 - val_loss: 0.0053 - val_mse: 0.0125\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0029 - val_loss: 0.0052 - val_mse: 0.0124\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0013 - mse: 0.0028 - val_loss: 0.0052 - val_mse: 0.0124\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - mse: 0.0028 - val_loss: 0.0052 - val_mse: 0.0123\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - mse: 0.0028 - val_loss: 0.0052 - val_mse: 0.0122\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0028 - val_loss: 0.0052 - val_mse: 0.0122\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0028 - val_loss: 0.0052 - val_mse: 0.0122\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0028 - val_loss: 0.0051 - val_mse: 0.0121\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0028 - val_loss: 0.0051 - val_mse: 0.0121\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0027 - val_loss: 0.0051 - val_mse: 0.0121\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0027 - val_loss: 0.0051 - val_mse: 0.0121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti2p25BIJ8NB",
        "outputId": "d29e9281-5db4-40b6-f4cb-4614df674e8b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x2262f10cc10>]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl4oDALoJ8NC"
      },
      "source": [
        "import numpy as np\n",
        "def threshold(model, train_scaled):\n",
        "    pred_train = model.predict(train_scaled)\n",
        "    error = tf.keras.losses.msle(pred_train,train_scaled )\n",
        "    \n",
        "    threshold1 = np.mean(error.numpy())+ np.std(error.numpy())\n",
        "    return threshold1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4yIkjOcJ8NC"
      },
      "source": [
        "def prediction_test(model, test_scaled, threshold1):\n",
        "    pred_test = model.predict(test_scaled)\n",
        "    error_test = tf.keras.losses.msle(pred_test,test_scaled )\n",
        "    \n",
        "    anamolies = pd.Series(error_test)> threshold1\n",
        "    prediction= anamolies.map(lambda x: 0.0 if x==True else 1.0)\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H1ioRqXJ8NE"
      },
      "source": [
        "th = threshold(model, train_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVJirK2yJ8NE"
      },
      "source": [
        "pred = prediction_test(model, test_scaled, th)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfSILnTVJ8NF"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(ytest, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfIzvNXAN2vU"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}